jax_env: False

seed: 0
algo: sac

# Environment configuration
env:
  env_id: "PegInsertionSide-v1"
  max_episode_steps: 200
  env_kwargs:
    control_mode: "pd_ee_delta_pose"
    # reward_config:
    #   static_reward: True
    #   stage_scaler: 2
    #   grasp_reward: True
    #   scale_reward: True
eval_env:
  max_episode_steps: 200

sac:
  num_seed_steps: 4_000
  replay_buffer_capacity: 100_000
  batch_size: 1024
  num_envs: 8
  steps_per_env: 8
  grad_updates_per_step: 32

  discount: 0.8
  tau: 0.01
  backup_entropy: False 

  eval_freq: 200
  eval_steps: 200
  num_eval_envs: 0

  log_freq: 16
  save_freq: 200

  learnable_temp: True
  initial_temperature: 1.0
  
model:
  actor_lr: 3e-4
  critic_lr: 3e-4

train: 
  steps: 400_000

logger:
  tensorboard: True
  wandb: False

  workspace: "robojax_exps"
  project_name: "robojax"
  wandb_cfg:
    group: "maniskill2_reward_bench"