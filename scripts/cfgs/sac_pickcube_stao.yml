jax_env: False

seed: 0
algo: sac

# Environment configuration
env:
  env_id: "PickCube-v1"
  max_episode_steps: 100
  env_kwargs:
    control_mode: "pd_ee_delta_pos"
    reward_config:
      static_reward: True
      stage_scaler: 2
      grasp_reward: True
      scale_reward: True
eval_env:
  max_episode_steps: 200

sac:
  num_seed_steps: 4_000
  replay_buffer_capacity: 1_000_000
  batch_size: 1024
  num_envs: 4
  steps_per_env: 1
  grad_updates_per_step: 2

  discount: 0.8
  # tau: 0.01
  # backup_entropy: False

  eval_freq: 10_000
  eval_steps: 200
  num_eval_envs: 4

  log_freq: 1000
  save_freq: 10_00

  learnable_temp: True
  initial_temperature: 1.0
  
model:
  actor_lr: 3e-4
  critic_lr: 3e-4

train: 
  steps: 80_000

logger:
  tensorboard: True
  wandb: False

  workspace: "robojax_exps"
  project_name: "robojax"
  wandb_cfg:
    group: "maniskill2_reward_bench"