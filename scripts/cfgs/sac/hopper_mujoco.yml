seed: 0
algo: sac

# Environment configuration
env:
  env_id: "Hopper-v4"
  num_envs: 4
  max_episode_steps: 1000
  jax_env: False
  env_kwargs:
    render_mode: "rgb_array"
eval_env:
  num_envs: 4
  max_episode_steps: 1000

sac:
  num_seed_steps: 5_000
  replay_buffer_capacity: 1_000_000
  batch_size: 256
  
  steps_per_env: 4
  grad_updates_per_step: 16

  eval_freq: 100_000
  eval_steps: 1_000

  log_freq: 1_000
  save_freq: 100_000

  learnable_temp: True
  initial_temperature: 1.0

network:
  actor:
    type: "mlp"
    arch_cfg:
      features: [256, 256, 256]
      output_activation: "relu"
  critic:
    type: "mlp"
    arch_cfg:
      features: [256, 256, 256]
      output_activation: "relu"

train:
  actor_lr: 3e-4
  critic_lr: 3e-4
  steps: 1_000_000

logger:
  tensorboard: True
  wandb: False

  workspace: "robojax_exps"
  project_name: "robojax"
  wandb_cfg:
    group: "benchmark"